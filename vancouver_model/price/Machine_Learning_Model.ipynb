{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from skopt import BayesSearchCV\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import math  \n",
    "import sklearn.metrics\n",
    "import shap\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Feature pre-processing\n",
    "#### Numerical Features\n",
    "'id', 'scrape_id', 'host_id', 'host_response_rate', 'host_acceptance_rate', 'host_listings_count', \n",
    "'host_total_listings_count','latitude', 'longitude', 'accommodates', 'bedrooms', 'beds', 'price',\n",
    "'minimum_nights', 'maximum_nights', 'minimum_minimum_nights', 'maximum_minimum_nights',\n",
    "'minimum_maximum_nights', 'maximum_maximum_nights', 'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm', \n",
    "'availability_30', 'availability_60', 'availability_90', 'availability_365', 'number_of_reviews',\n",
    "'number_of_reviews_ltm','number_of_reviews_l30d','review_scores_rating','review_scores_accuracy',\n",
    "'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', \n",
    "'review_scores_value','calculated_host_listings_count', 'calculated_host_listings_count_entire_homes',\n",
    "'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms','reviews_per_month'\n",
    "\n",
    "#### Categorical Features\n",
    "'source', 'host_response_time', 'host_is_superhost', 'host_neighbourhood', 'host_has_profile_pic', \n",
    "'host_identity_verified', 'neighbourhood', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed', \n",
    "'property_type','room_type', 'has_availability', 'instant_bookable', 'host_location'\n",
    "\n",
    "#### Date Features\n",
    "'last_scraped', 'host_since', 'calendar_last_scraped', 'first_review', 'last_review'\n",
    "\n",
    "#### Text Features\n",
    "'listing_url', 'name', 'description', 'neighbourhood_overview', 'picture_url', \n",
    "'host_url', 'host_name', 'host_about', 'hosr_thumbnail_url', 'host_picture_url', \n",
    "'host_verifications', 'bathrooms_text', 'amenities'\n",
    "\n",
    "#### Empty Columns\n",
    "'calendar_updated', 'bathrooms'\n",
    "\n",
    "#### Dummu Column\n",
    "'license'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('listings.csv')\n",
    "airbnb = pd.read_csv('airbnb_4.csv')\n",
    "# Merge the two dataframes based on the 'id' column, concatenate 3 new features\n",
    "merged_df = pd.merge(data, airbnb[['id', 'average_nearest_price', 'within_radius', 'bus_radius']], on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4887 entries, 0 to 4886\n",
      "Data columns (total 78 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   id                                            4887 non-null   int64  \n",
      " 1   listing_url                                   4887 non-null   object \n",
      " 2   scrape_id                                     4887 non-null   int64  \n",
      " 3   last_scraped                                  4887 non-null   object \n",
      " 4   source                                        4887 non-null   object \n",
      " 5   name                                          4887 non-null   object \n",
      " 6   description                                   4866 non-null   object \n",
      " 7   neighborhood_overview                         3422 non-null   object \n",
      " 8   picture_url                                   4887 non-null   object \n",
      " 9   host_id                                       4887 non-null   int64  \n",
      " 10  host_url                                      4887 non-null   object \n",
      " 11  host_name                                     4887 non-null   object \n",
      " 12  host_since                                    4887 non-null   object \n",
      " 13  host_location                                 4019 non-null   object \n",
      " 14  host_about                                    2816 non-null   object \n",
      " 15  host_response_time                            3900 non-null   object \n",
      " 16  host_response_rate                            3900 non-null   object \n",
      " 17  host_acceptance_rate                          4135 non-null   object \n",
      " 18  host_is_superhost                             4887 non-null   object \n",
      " 19  host_thumbnail_url                            4887 non-null   object \n",
      " 20  host_picture_url                              4887 non-null   object \n",
      " 21  host_neighbourhood                            4599 non-null   object \n",
      " 22  host_listings_count                           4887 non-null   int64  \n",
      " 23  host_total_listings_count                     4887 non-null   int64  \n",
      " 24  host_verifications                            4887 non-null   object \n",
      " 25  host_has_profile_pic                          4887 non-null   object \n",
      " 26  host_identity_verified                        4887 non-null   object \n",
      " 27  neighbourhood                                 3422 non-null   object \n",
      " 28  neighbourhood_cleansed                        4887 non-null   object \n",
      " 29  neighbourhood_group_cleansed                  0 non-null      float64\n",
      " 30  latitude                                      4887 non-null   float64\n",
      " 31  longitude                                     4887 non-null   float64\n",
      " 32  property_type                                 4887 non-null   object \n",
      " 33  room_type                                     4887 non-null   object \n",
      " 34  accommodates                                  4887 non-null   int64  \n",
      " 35  bathrooms                                     0 non-null      float64\n",
      " 36  bathrooms_text                                4885 non-null   object \n",
      " 37  bedrooms                                      4588 non-null   float64\n",
      " 38  beds                                          4843 non-null   float64\n",
      " 39  amenities                                     4887 non-null   object \n",
      " 40  price                                         4887 non-null   object \n",
      " 41  minimum_nights                                4887 non-null   int64  \n",
      " 42  maximum_nights                                4887 non-null   int64  \n",
      " 43  minimum_minimum_nights                        4887 non-null   int64  \n",
      " 44  maximum_minimum_nights                        4887 non-null   int64  \n",
      " 45  minimum_maximum_nights                        4887 non-null   int64  \n",
      " 46  maximum_maximum_nights                        4887 non-null   int64  \n",
      " 47  minimum_nights_avg_ntm                        4887 non-null   float64\n",
      " 48  maximum_nights_avg_ntm                        4887 non-null   float64\n",
      " 49  calendar_updated                              0 non-null      float64\n",
      " 50  has_availability                              4887 non-null   object \n",
      " 51  availability_30                               4887 non-null   int64  \n",
      " 52  availability_60                               4887 non-null   int64  \n",
      " 53  availability_90                               4887 non-null   int64  \n",
      " 54  availability_365                              4887 non-null   int64  \n",
      " 55  calendar_last_scraped                         4887 non-null   object \n",
      " 56  number_of_reviews                             4887 non-null   int64  \n",
      " 57  number_of_reviews_ltm                         4887 non-null   int64  \n",
      " 58  number_of_reviews_l30d                        4887 non-null   int64  \n",
      " 59  first_review                                  4358 non-null   object \n",
      " 60  last_review                                   4358 non-null   object \n",
      " 61  review_scores_rating                          4358 non-null   float64\n",
      " 62  review_scores_accuracy                        4346 non-null   float64\n",
      " 63  review_scores_cleanliness                     4346 non-null   float64\n",
      " 64  review_scores_checkin                         4346 non-null   float64\n",
      " 65  review_scores_communication                   4346 non-null   float64\n",
      " 66  review_scores_location                        4346 non-null   float64\n",
      " 67  review_scores_value                           4346 non-null   float64\n",
      " 68  license                                       3499 non-null   object \n",
      " 69  instant_bookable                              4887 non-null   object \n",
      " 70  calculated_host_listings_count                4887 non-null   int64  \n",
      " 71  calculated_host_listings_count_entire_homes   4887 non-null   int64  \n",
      " 72  calculated_host_listings_count_private_rooms  4887 non-null   int64  \n",
      " 73  calculated_host_listings_count_shared_rooms   4887 non-null   int64  \n",
      " 74  reviews_per_month                             4358 non-null   float64\n",
      " 75  average_nearest_price                         4882 non-null   float64\n",
      " 76  within_radius                                 4887 non-null   bool   \n",
      " 77  bus_radius                                    4887 non-null   bool   \n",
      "dtypes: bool(2), float64(18), int64(23), object(35)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since we face to new host, we select the features that is relevant to the feature price, ignored empty columns, identification features (id, name, etc.), high correlated featurs (host_listings_count, minimum_minimum_nights, etc), and past experience features, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19 selected features\n",
    "columns = ['latitude', 'longitude', 'host_total_listings_count','host_has_profile_pic', \n",
    "           'host_identity_verified','neighbourhood_cleansed', 'property_type', 'room_type', \n",
    "           'accommodates', 'bathrooms_text', 'bedrooms', 'beds', 'amenities', 'price', 'has_availability', 'instant_bookable', 'calculated_host_listings_count', \n",
    "            'average_nearest_price', 'within_radius', 'bus_radius']\n",
    "df = merged_df[columns].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Count the number of NA in each column, and drop all rows have NA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitude: 0\n",
      "longitude: 0\n",
      "host_total_listings_count: 0\n",
      "host_has_profile_pic: 0\n",
      "host_identity_verified: 0\n",
      "neighbourhood_cleansed: 0\n",
      "property_type: 0\n",
      "room_type: 0\n",
      "accommodates: 0\n",
      "bathrooms_text: 2\n",
      "bedrooms: 299\n",
      "beds: 44\n",
      "amenities: 0\n",
      "price: 0\n",
      "has_availability: 0\n",
      "instant_bookable: 0\n",
      "calculated_host_listings_count: 0\n",
      "average_nearest_price: 5\n",
      "within_radius: 0\n",
      "bus_radius: 0\n"
     ]
    }
   ],
   "source": [
    "def count_na_by_column(data):\n",
    "    for column in data.columns:\n",
    "        print(column + \":\", data[column].isna().sum())\n",
    "count_na_by_column(df)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Convert the price to numeric values [extreme value removed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    157.0\n",
       "1    150.0\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prices_to_numbers (price_string):\n",
    "    price_numeric = float(str(price_string).replace(',', '').split('$')[-1])\n",
    "    return price_numeric\n",
    "df['price'] = df['price'].apply(prices_to_numbers)\n",
    "df.price.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_high = df['price'].quantile(0.95)\n",
    "q_low = df['price'].quantile(0.05)\n",
    "df = df[(df['price'] <= q_high) & (df['price'] >= q_low)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Convert bool value to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mappings for host_has_profile_pic: {0: 'f', 1: 't'}\n",
      "\n",
      "Mappings for host_identity_verified: {0: 'f', 1: 't'}\n",
      "\n",
      "Mappings for has_availability: {0: 'f', 1: 't'}\n",
      "\n",
      "Mappings for instant_bookable: {0: 'f', 1: 't'}\n",
      "\n",
      "Mappings for within_radius: {0: False, 1: True}\n",
      "\n",
      "Mappings for bus_radius: {0: False, 1: True}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "boolean_cols = ['host_has_profile_pic',\n",
    "               'host_identity_verified',\n",
    "               'has_availability',\n",
    "               'instant_bookable',\n",
    "               'within_radius',\n",
    "               'bus_radius']\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in boolean_cols:\n",
    "    col_encoded = le.fit_transform(df[col])\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    # get the mappings of the encoded values\n",
    "    mappings = dict(zip(range(len(le.classes_)), le.classes_))\n",
    "\n",
    "    # print the mappings\n",
    "    print(\"Mappings for %s: %s\\n\" % (col, mappings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extract all kind of amenities from the text, create new amenity boolean features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_amenities = []\n",
    "amenities_list = df.amenities.unique()\n",
    "\n",
    "for i in range(len(amenities_list)):\n",
    "    amenities = amenities_list[i].split(\",\")\n",
    "    for ft in amenities:\n",
    "        for amen in ft.split('\"'):\n",
    "            if amen != \"[\" and amen != \"]\" and amen not in all_amenities:\n",
    "                all_amenities.append(amen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We manually selected a few hot amenities to create new boolean features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['amenities'].str.contains('Air conditioning|Central air conditioning'), 'air_conditioning'] = 1\n",
    "df.loc[df['amenities'].str.contains('Amazon Echo|Apple TV|Game console|Netflix|Projector and screen|Smart TV'), 'high_end_electronics'] = 1\n",
    "df.loc[df['amenities'].str.contains('BBQ grill|Fire pit|Propane barbeque'), 'bbq'] = 1\n",
    "df.loc[df['amenities'].str.contains('Balcony|Patio'), 'balcony'] = 1\n",
    "df.loc[df['amenities'].str.contains('Beach view|Beachfront|Lake access|Mountain view|Ski-in/Ski-out|Waterfront'), 'nature_and_views'] = 1\n",
    "df.loc[df['amenities'].str.contains('Bed linens'), 'bed_linen'] = 1\n",
    "df.loc[df['amenities'].str.contains('Breakfast'), 'breakfast'] = 1\n",
    "df.loc[df['amenities'].str.contains('TV'), 'tv'] = 1\n",
    "df.loc[df['amenities'].str.contains('Coffee maker|Espresso machine'), 'coffee_machine'] = 1\n",
    "df.loc[df['amenities'].str.contains('Cooking basics'), 'cooking_basics'] = 1\n",
    "df.loc[df['amenities'].str.contains('Dishwasher|Dryer|Washer'), 'white_goods'] = 1\n",
    "df.loc[df['amenities'].str.contains('Elevator'), 'elevator'] = 1\n",
    "df.loc[df['amenities'].str.contains('Exercise equipment|Gym|gym'), 'gym'] = 1\n",
    "df.loc[df['amenities'].str.contains('Family/kid friendly|Children|children'), 'child_friendly'] = 1\n",
    "df.loc[df['amenities'].str.contains('parking'), 'parking'] = 1\n",
    "df.loc[df['amenities'].str.contains('Garden|Outdoor|Sun loungers|Terrace'), 'outdoor_space'] = 1\n",
    "df.loc[df['amenities'].str.contains('Host greets you'), 'host_greeting'] = 1\n",
    "df.loc[df['amenities'].str.contains('Hot tub|Jetted tub|hot tub|Sauna|Pool|pool'), 'hot_tub_sauna_or_pool'] = 1\n",
    "df.loc[df['amenities'].str.contains('Internet|Pocket wifi|Wifi'), 'internet'] = 1\n",
    "df.loc[df['amenities'].str.contains('Long term stays allowed'), 'long_term_stays'] = 1\n",
    "df.loc[df['amenities'].str.contains('Pets|pet|Cat(s)|Dog(s)'), 'pets_allowed'] = 1\n",
    "df.loc[df['amenities'].str.contains('Private entrance'), 'private_entrance'] = 1\n",
    "df.loc[df['amenities'].str.contains('Safe|Security system'), 'secure'] = 1\n",
    "df.loc[df['amenities'].str.contains('Smoking allowed'), 'smoking_allowed'] = 1\n",
    "#df.loc[df['amenities'].str.contains('Suitable for events'), 'event_suitable'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4095 entries, 0 to 4886\n",
      "Data columns (total 44 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   latitude                        4095 non-null   float64\n",
      " 1   longitude                       4095 non-null   float64\n",
      " 2   host_total_listings_count       4095 non-null   int64  \n",
      " 3   host_has_profile_pic            4095 non-null   int32  \n",
      " 4   host_identity_verified          4095 non-null   int32  \n",
      " 5   neighbourhood_cleansed          4095 non-null   object \n",
      " 6   property_type                   4095 non-null   object \n",
      " 7   room_type                       4095 non-null   object \n",
      " 8   accommodates                    4095 non-null   int64  \n",
      " 9   bathrooms_text                  4095 non-null   object \n",
      " 10  bedrooms                        4095 non-null   float64\n",
      " 11  beds                            4095 non-null   float64\n",
      " 12  amenities                       4095 non-null   object \n",
      " 13  price                           4095 non-null   float64\n",
      " 14  has_availability                4095 non-null   int32  \n",
      " 15  instant_bookable                4095 non-null   int32  \n",
      " 16  calculated_host_listings_count  4095 non-null   int64  \n",
      " 17  average_nearest_price           4095 non-null   float64\n",
      " 18  within_radius                   4095 non-null   int64  \n",
      " 19  bus_radius                      4095 non-null   int64  \n",
      " 20  air_conditioning                978 non-null    float64\n",
      " 21  high_end_electronics            944 non-null    float64\n",
      " 22  bbq                             727 non-null    float64\n",
      " 23  balcony                         587 non-null    float64\n",
      " 24  nature_and_views                663 non-null    float64\n",
      " 25  bed_linen                       2790 non-null   float64\n",
      " 26  breakfast                       146 non-null    float64\n",
      " 27  tv                              3622 non-null   float64\n",
      " 28  coffee_machine                  3079 non-null   float64\n",
      " 29  cooking_basics                  3145 non-null   float64\n",
      " 30  white_goods                     3409 non-null   float64\n",
      " 31  elevator                        1565 non-null   float64\n",
      " 32  gym                             1418 non-null   float64\n",
      " 33  child_friendly                  535 non-null    float64\n",
      " 34  parking                         3665 non-null   float64\n",
      " 35  outdoor_space                   1338 non-null   float64\n",
      " 36  host_greeting                   538 non-null    float64\n",
      " 37  hot_tub_sauna_or_pool           822 non-null    float64\n",
      " 38  internet                        3646 non-null   float64\n",
      " 39  long_term_stays                 2176 non-null   float64\n",
      " 40  pets_allowed                    865 non-null    float64\n",
      " 41  private_entrance                2065 non-null   float64\n",
      " 42  secure                          207 non-null    float64\n",
      " 43  smoking_allowed                 42 non-null     float64\n",
      "dtypes: float64(30), int32(4), int64(5), object(5)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing nulls with zeros for new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_replace_nulls = df.iloc[:,20:].columns\n",
    "df[cols_to_replace_nulls] = df[cols_to_replace_nulls].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we view the value set for all new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "air_conditioning {0.0, 1.0}\n",
      "high_end_electronics {0.0, 1.0}\n",
      "bbq {0.0, 1.0}\n",
      "balcony {0.0, 1.0}\n",
      "nature_and_views {0.0, 1.0}\n",
      "bed_linen {0.0, 1.0}\n",
      "breakfast {0.0, 1.0}\n",
      "tv {0.0, 1.0}\n",
      "coffee_machine {0.0, 1.0}\n",
      "cooking_basics {0.0, 1.0}\n",
      "white_goods {0.0, 1.0}\n",
      "elevator {0.0, 1.0}\n",
      "gym {0.0, 1.0}\n",
      "child_friendly {0.0, 1.0}\n",
      "parking {0.0, 1.0}\n",
      "outdoor_space {0.0, 1.0}\n",
      "host_greeting {0.0, 1.0}\n",
      "hot_tub_sauna_or_pool {0.0, 1.0}\n",
      "internet {0.0, 1.0}\n",
      "long_term_stays {0.0, 1.0}\n",
      "pets_allowed {0.0, 1.0}\n",
      "private_entrance {0.0, 1.0}\n",
      "secure {0.0, 1.0}\n",
      "smoking_allowed {0.0, 1.0}\n"
     ]
    }
   ],
   "source": [
    "def printValuesForEachColumn(data):\n",
    "    for amenity_column in data.columns[20:]:\n",
    "        print(amenity_column, set(data[amenity_column]))\n",
    "printValuesForEachColumn(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did not observe any column contains a single value only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the original amenities column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('amenities', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Displays the property type of listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entire condo                          1189\n",
       "Entire rental unit                     792\n",
       "Entire home                            634\n",
       "Entire guest suite                     545\n",
       "Private room in home                   319\n",
       "Entire loft                            119\n",
       "Entire townhouse                        80\n",
       "Private room in rental unit             70\n",
       "Private room in condo                   65\n",
       "Entire guesthouse                       62\n",
       "Entire serviced apartment               57\n",
       "Private room in villa                   27\n",
       "Private room in townhouse               23\n",
       "Private room in guest suite             16\n",
       "Entire villa                            11\n",
       "Entire bungalow                         10\n",
       "Room in boutique hotel                   9\n",
       "Private room in bed and breakfast        8\n",
       "Entire place                             6\n",
       "Room in aparthotel                       5\n",
       "Private room in bungalow                 4\n",
       "Entire timeshare                         4\n",
       "Entire cottage                           4\n",
       "Private room in serviced apartment       4\n",
       "Entire vacation home                     4\n",
       "Tiny home                                4\n",
       "Room in bed and breakfast                3\n",
       "Private room in hostel                   3\n",
       "Shared room in rental unit               2\n",
       "Private room in loft                     2\n",
       "Private room in guesthouse               2\n",
       "Private room in resort                   2\n",
       "Camper/RV                                2\n",
       "Private room in vacation home            1\n",
       "Floor                                    1\n",
       "Private room in tiny home                1\n",
       "Private room in camper/rv                1\n",
       "Private room in boat                     1\n",
       "Shared room in loft                      1\n",
       "Private room in cottage                  1\n",
       "Room in hotel                            1\n",
       "Name: property_type, dtype: int64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "property_type_counts = df.property_type.value_counts()\n",
    "property_type_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping property types whose low counts might be insignificant and not provide us with enough information.\n",
    "Thus, grouping property types that have counts that are < 20 into 'Other'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entire condo                   1189\n",
       "Entire rental unit              792\n",
       "Entire home                     634\n",
       "Entire guest suite              545\n",
       "Private room in home            319\n",
       "Entire loft                     119\n",
       "Other                           113\n",
       "Entire townhouse                 80\n",
       "Private room in rental unit      70\n",
       "Private room in condo            65\n",
       "Entire guesthouse                62\n",
       "Entire serviced apartment        57\n",
       "Private room in villa            27\n",
       "Private room in townhouse        23\n",
       "Name: property_type, dtype: int64"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.property_type.isin(property_type_counts[property_type_counts<20].keys()), 'property_type'] = 'Other'\n",
    "df.property_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Extract the features of bathrooms number and bathroom type from the text column 'bathrooms_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5 baths',\n",
       " '4.5 baths',\n",
       " '1.5 shared baths',\n",
       " '4 baths',\n",
       " '1.5 baths',\n",
       " '1 shared bath',\n",
       " '0 baths',\n",
       " '0 shared baths',\n",
       " '2.5 baths',\n",
       " '1 bath']"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(df.bathrooms_text))[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    3587\n",
       "private     254\n",
       "shared      254\n",
       "Name: bathrooms_type, dtype: int64"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convertBathrooms(row):  \n",
    "    if 'private' in row['bathrooms_text'].lower():\n",
    "        return 'private'\n",
    "    elif 'shared' in row['bathrooms_text'].lower():\n",
    "        return 'shared'\n",
    "    return 'unknown'\n",
    "\n",
    "df['bathrooms_type'] = df.apply(lambda row: convertBathrooms(row), axis=1)\n",
    "df.bathrooms_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we extract the bathroom number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    3023\n",
       "2.0     704\n",
       "1.5     191\n",
       "2.5     107\n",
       "3.0      34\n",
       "3.5      16\n",
       "4.0       8\n",
       "4.5       4\n",
       "0.0       3\n",
       "0.5       2\n",
       "6.0       1\n",
       "5.0       1\n",
       "7.0       1\n",
       "Name: bathrooms_number, dtype: int64"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculateBathroomNum(row):  \n",
    "    if 'half' in row['bathrooms_text'].lower() or 'Half' in row['bathrooms_text'].lower():\n",
    "        return 0.5\n",
    "    return float(row['bathrooms_text'].split(\" \")[0])\n",
    "\n",
    "df['bathrooms_number'] = df.apply(lambda row: calculateBathroomNum(row), axis=1)\n",
    "df.bathrooms_number.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the original column 'bathrooms_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('bathrooms_text', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Encode other categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mappings for neighbourhood_cleansed: {0: 'Arbutus Ridge', 1: 'Downtown', 2: 'Downtown Eastside', 3: 'Dunbar Southlands', 4: 'Fairview', 5: 'Grandview-Woodland', 6: 'Hastings-Sunrise', 7: 'Kensington-Cedar Cottage', 8: 'Kerrisdale', 9: 'Killarney', 10: 'Kitsilano', 11: 'Marpole', 12: 'Mount Pleasant', 13: 'Oakridge', 14: 'Renfrew-Collingwood', 15: 'Riley Park', 16: 'Shaughnessy', 17: 'South Cambie', 18: 'Strathcona', 19: 'Sunset', 20: 'Victoria-Fraserview', 21: 'West End', 22: 'West Point Grey'}\n",
      "\n",
      "Mappings for property_type: {0: 'Entire condo', 1: 'Entire guest suite', 2: 'Entire guesthouse', 3: 'Entire home', 4: 'Entire loft', 5: 'Entire rental unit', 6: 'Entire serviced apartment', 7: 'Entire townhouse', 8: 'Other', 9: 'Private room in condo', 10: 'Private room in home', 11: 'Private room in rental unit', 12: 'Private room in townhouse', 13: 'Private room in villa'}\n",
      "\n",
      "Mappings for room_type: {0: 'Entire home/apt', 1: 'Hotel room', 2: 'Private room', 3: 'Shared room'}\n",
      "\n",
      "Mappings for bathrooms_type: {0: 'private', 1: 'shared', 2: 'unknown'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "boolean_cols = ['neighbourhood_cleansed',\n",
    "               'property_type',\n",
    "               'room_type',\n",
    "               'bathrooms_type']\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in boolean_cols:\n",
    "    col_encoded = le.fit_transform(df[col])\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    # get the mappings of the encoded values\n",
    "    mappings = dict(zip(range(len(le.classes_)), le.classes_))\n",
    "\n",
    "    # print the mappings\n",
    "    print(\"Mappings for %s: %s\\n\" % (col, mappings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('airbnb_model_fitting.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != 'price']\n",
    "y = df['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.1, train_size = 0.9,  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitude: 0\n",
      "longitude: 0\n",
      "host_total_listings_count: 0\n",
      "host_has_profile_pic: 0\n",
      "host_identity_verified: 0\n",
      "neighbourhood_cleansed: 0\n",
      "property_type: 0\n",
      "room_type: 0\n",
      "accommodates: 0\n",
      "bedrooms: 0\n",
      "beds: 0\n",
      "has_availability: 0\n",
      "instant_bookable: 0\n",
      "calculated_host_listings_count: 0\n",
      "average_nearest_price: 0\n",
      "within_radius: 0\n",
      "bus_radius: 0\n",
      "air_conditioning: 0\n",
      "high_end_electronics: 0\n",
      "bbq: 0\n",
      "balcony: 0\n",
      "nature_and_views: 0\n",
      "bed_linen: 0\n",
      "breakfast: 0\n",
      "tv: 0\n",
      "coffee_machine: 0\n",
      "cooking_basics: 0\n",
      "white_goods: 0\n",
      "elevator: 0\n",
      "gym: 0\n",
      "child_friendly: 0\n",
      "parking: 0\n",
      "outdoor_space: 0\n",
      "host_greeting: 0\n",
      "hot_tub_sauna_or_pool: 0\n",
      "internet: 0\n",
      "long_term_stays: 0\n",
      "pets_allowed: 0\n",
      "private_entrance: 0\n",
      "secure: 0\n",
      "smoking_allowed: 0\n",
      "bathrooms_type: 0\n",
      "bathrooms_number: 0\n"
     ]
    }
   ],
   "source": [
    "count_na_by_column(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3685 entries, 4657 to 3839\n",
      "Data columns (total 14 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   longitude                       3685 non-null   float64\n",
      " 1   host_total_listings_count       3685 non-null   int64  \n",
      " 2   neighbourhood_cleansed          3685 non-null   int32  \n",
      " 3   property_type                   3685 non-null   int32  \n",
      " 4   room_type                       3685 non-null   int32  \n",
      " 5   accommodates                    3685 non-null   int64  \n",
      " 6   bedrooms                        3685 non-null   float64\n",
      " 7   beds                            3685 non-null   float64\n",
      " 8   calculated_host_listings_count  3685 non-null   int64  \n",
      " 9   bathrooms_type                  3685 non-null   int32  \n",
      " 10  bathrooms_number                3685 non-null   float64\n",
      " 11  bus_radius                      3685 non-null   int64  \n",
      " 12  within_radius                   3685 non-null   int64  \n",
      " 13  average_nearest_price           3685 non-null   float64\n",
      "dtypes: float64(5), int32(4), int64(5)\n",
      "memory usage: 374.3 KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression,mutual_info_regression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "selector = SelectKBest(mutual_info_regression, k=11)\n",
    "\n",
    "X_new = selector.fit_transform(X_train, y_train)\n",
    "\n",
    "X_train_selected = X_train.iloc[:, selector.get_support(indices=True)]\n",
    "X_test_selected = X_test.iloc[:, selector.get_support(indices=True)]\n",
    "\n",
    "X_train_selected['bus_radius'] = X_train.iloc[:, X_train.columns.get_loc('bus_radius')]\n",
    "X_train_selected['within_radius'] = X_train['within_radius']\n",
    "X_train_selected['average_nearest_price'] = X_train['average_nearest_price']\n",
    "X_train_selected['longitude'] = X_train['longitude']\n",
    "\n",
    "X_test_selected['bus_radius'] = X_test['bus_radius']\n",
    "X_test_selected['within_radius'] = X_test['within_radius']\n",
    "X_test_selected['average_nearest_price'] = X_test['average_nearest_price']\n",
    "X_test_selected['longitude'] = X_test['longitude']\n",
    "\n",
    "X_train_selected.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "regressor = RandomForestRegressor(n_estimators = 40, max_features = 'sqrt', max_depth = 50)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "feature_importances = regressor.feature_importances_\n",
    "\n",
    "# Create a pandas dataframe of feature importances\n",
    "df_importances = pd.DataFrame({'feature': list(range(X_train.shape[1])), 'importance': feature_importances}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Select features with highest importance scores\n",
    "top_features = df_importances[df_importances['importance'] >= 0.013]['feature'].values.tolist()\n",
    "\n",
    "X_train_selected = X_train.iloc[:, top_features]\n",
    "X_test_selected = X_test.iloc[:, top_features]\n",
    "X_train_selected.info()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE, Test Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected.to_csv('preprocessed_X_train.csv',index=False)\n",
    "y_train.to_csv('preprocessed_y_train.csv',index=False)\n",
    "X_test_selected.to_csv('preprocessed_X_test.csv',index=False)\n",
    "y_test.to_csv('preprocessed_y_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nbconvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjupyter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnbconvert\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--to\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnotebook\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--execute\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeature_patch_1.ipynb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:364\u001b[0m, in \u001b[0;36mcheck_call\u001b[1;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_call\u001b[39m(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;124;03m\"\"\"Run command with arguments.  Wait for command to complete.  If\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;124;03m    the exit code was zero then return, otherwise raise\u001b[39;00m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;124;03m    CalledProcessError.  The CalledProcessError object will have the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;124;03m    check_call([\"ls\", \"-l\"])\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 364\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m call(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retcode:\n\u001b[0;32m    366\u001b[0m         cmd \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:347\u001b[0m, in \u001b[0;36mcall\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 347\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:  \u001b[38;5;66;03m# Including KeyboardInterrupt, wait handled that.\u001b[39;00m\n\u001b[0;32m    349\u001b[0m         p\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:1207\u001b[0m, in \u001b[0;36mPopen.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1205\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1209\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[0;32m   1210\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py:1488\u001b[0m, in \u001b[0;36mPopen._wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1485\u001b[0m     timeout_millis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m     \u001b[38;5;66;03m# API note: Returns immediately if timeout_millis == 0.\u001b[39;00m\n\u001b[1;32m-> 1488\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForSingleObject\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mtimeout_millis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;241m==\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mWAIT_TIMEOUT:\n\u001b[0;32m   1491\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TimeoutExpired(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, timeout)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "subprocess.check_call(['jupyter', 'nbconvert', '--to', 'notebook', '--execute', 'feature_patch_1.ipynb'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree regression is a technique that is able to perform both regression and classification task with decision tree. Since our dataset contains many categorical variables, we choose to use the tree regressor becuase it potentially more friendly with categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Trained without average nearby listing price feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1 = X_train_selected\n",
    "y_train_1 = y_train\n",
    "\n",
    "X_test_1 = pd.read_csv('preprocessed_2_X_test_1.csv', sep=',')\n",
    "y_test_1 = pd.read_csv('preprocessed_2_y_test_1.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 50, max_features = 'sqrt', max_depth = 30, random_state=42)\n",
    "rf.fit(X_train_1, y_train_1)\n",
    "y_predict_rf = rf.predict(X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importancesRF = rf.feature_importances_\n",
    "feat_imp1 = pd.DataFrame(importancesRF, columns=['Weight'], index=X_train_1.columns)\n",
    "feat_imp1.sort_values('Weight', inplace=True, ascending=False)\n",
    "feat_imp1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = pd.DataFrame({'importance':rf.feature_importances_})  \n",
    "feat_imp['feature'] = X_train_1.columns\n",
    "feat_imp.sort_values(by='importance', ascending=False, inplace=True)\n",
    "\n",
    "feat_imp.sort_values(by='importance', inplace=True)\n",
    "feat_imp = feat_imp.set_index('feature', drop=True)\n",
    "feat_imp = feat_imp[len(feat_imp1)-15:len(feat_imp1)]\n",
    "feat_imp.plot.barh(figsize=(5,5))\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('15 Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = sklearn.metrics.mean_squared_error(y_test_1, y_predict_rf)  \n",
    "mae_rf_1 = sklearn.metrics.mean_absolute_error(y_test_1, y_predict_rf) \n",
    "\n",
    "rmse_rf_1 = math.sqrt(mse)  \n",
    "\n",
    "print(\"RMSE = \", rmse_rf_1)\n",
    "print(\"MAE = \", mae_rf_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_values = explainer.shap_values(X_test_1)\n",
    "\n",
    "shap.force_plot(explainer.expected_value, shap_values[0,:], X_test_1.iloc[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeRegressor(criterion='squared_error', max_depth = 20, random_state=42)\n",
    "\n",
    "decision_tree.fit(X_train_1, y_train_1)\n",
    "y_predict_dt = decision_tree.predict(X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importancesRF = decision_tree.feature_importances_\n",
    "feat_imp1 = pd.DataFrame(importancesRF, columns=['Weight'], index=X_train_1.columns)\n",
    "feat_imp1.sort_values('Weight', inplace=True, ascending=False)\n",
    "feat_imp1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_imp = pd.DataFrame({'importance':decision_tree.feature_importances_})  \n",
    "# feat_imp['feature'] = X_train_1.columns\n",
    "# feat_imp.sort_values(by='importance', ascending=False, inplace=True)\n",
    "\n",
    "# feat_imp.sort_values(by='importance', inplace=True)\n",
    "# feat_imp = feat_imp.set_index('feature', drop=True)\n",
    "# feat_imp = feat_imp[len(feat_imp1)-15:len(feat_imp1)]\n",
    "# feat_imp.plot.barh(figsize=(5,5))\n",
    "# plt.xlabel('Importance Score')\n",
    "# plt.ylabel('15 Features')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = sklearn.metrics.mean_squared_error(y_test_1, y_predict_dt)  \n",
    "mae_dt_1 = sklearn.metrics.mean_absolute_error(y_test_1, y_predict_dt) \n",
    "\n",
    "rmse_dt_1 = math.sqrt(mse)  \n",
    "\n",
    "print(\"RMSE = \", rmse_dt_1)\n",
    "print(\"MAE = \", mae_dt_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Gradient boosting regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_boosting_tree = GradientBoostingRegressor(n_estimators=50, learning_rate = 0.06, max_features = 'sqrt', \n",
    "                                               max_depth = 50, random_state=42)\n",
    "\n",
    "grad_boosting_tree.fit(X_train_1, y_train_1)\n",
    "y_predict_gb = grad_boosting_tree.predict(X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importancesRF = grad_boosting_tree.feature_importances_\n",
    "feat_imp1 = pd.DataFrame(importancesRF, columns=['Weight'], index=X_train_1.columns)\n",
    "feat_imp1.sort_values('Weight', inplace=True, ascending=False)\n",
    "feat_imp1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_imp = pd.DataFrame({'importance':grad_boosting_tree.feature_importances_})  \n",
    "# feat_imp['feature'] = X_train_1.columns\n",
    "# feat_imp.sort_values(by='importance', ascending=False, inplace=True)\n",
    "\n",
    "# feat_imp.sort_values(by='importance', inplace=True)\n",
    "# feat_imp = feat_imp.set_index('feature', drop=True)\n",
    "# feat_imp = feat_imp[len(feat_imp1)-15:len(feat_imp1)]\n",
    "# feat_imp.plot.barh(figsize=(5,5))\n",
    "# plt.xlabel('Importance Score')\n",
    "# plt.ylabel('15 Features')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = sklearn.metrics.mean_squared_error(y_test_1, y_predict_gb)  \n",
    "mae_gb_1 = sklearn.metrics.mean_absolute_error(y_test_1, y_predict_gb) \n",
    "\n",
    "rmse_gb_1 = math.sqrt(mse)  \n",
    "\n",
    "print(\"RMSE = \", rmse_gb_1)\n",
    "print(\"MAE = \", mae_gb_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(grad_boosting_tree)\n",
    "shap_values = explainer.shap_values(X_test_1)\n",
    "\n",
    "shap.force_plot(explainer.expected_value, shap_values[0,:], X_test_1.iloc[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Trained with average nearby listing price feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_2 = pd.read_csv('preprocessed_2_X_test_2.csv', sep=',')\n",
    "y_test_2 = pd.read_csv('preprocessed_2_y_test_2.csv', sep=',')\n",
    "X_train_2 = pd.read_csv('preprocessed_2_X_train.csv', sep=',')\n",
    "y_train_2 = pd.read_csv('preprocessed_2_y_train.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_2 = RandomForestRegressor(n_estimators = 30, max_features = 'sqrt', max_depth = 50, random_state=42)\n",
    "rf_2.fit(X_train_2, y_train_2)\n",
    "y_predict_rf_2 = rf_2.predict(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importancesRF = rf_2.feature_importances_\n",
    "feat_imp1 = pd.DataFrame(importancesRF, columns=['Weight'], index=X_train_2.columns)\n",
    "feat_imp1.sort_values('Weight', inplace=True, ascending=False)\n",
    "feat_imp1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = pd.DataFrame({'importance':rf_2.feature_importances_})  \n",
    "feat_imp['feature'] = X_train_2.columns\n",
    "\n",
    "feat_imp.sort_values(by='importance', inplace=True)\n",
    "feat_imp = feat_imp.set_index('feature', drop=True)\n",
    "feat_imp = feat_imp[len(feat_imp1)-16:len(feat_imp1)]\n",
    "feat_imp.plot.barh(figsize=(5,5))\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('16 Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = sklearn.metrics.mean_squared_error(y_test_2, y_predict_rf_2)  \n",
    "mae_rf_2 = sklearn.metrics.mean_absolute_error(y_test_2, y_predict_rf_2) \n",
    "\n",
    "rmse_rf_2 = math.sqrt(mse)  \n",
    "\n",
    "print(\"RMSE = \", rmse_rf_2)\n",
    "print(\"MAE = \", mae_rf_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(rf_2)\n",
    "shap_values = explainer.shap_values(X_test_2)\n",
    "\n",
    "shap.force_plot(explainer.expected_value, shap_values[0,:], X_test_2.iloc[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_2 = DecisionTreeRegressor(max_depth = 30, random_state=42)\n",
    "\n",
    "decision_tree_2.fit(X_train_2, y_train_2)\n",
    "y_predict_dt_2 = decision_tree_2.predict(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importancesRF = decision_tree_2.feature_importances_\n",
    "feat_imp1 = pd.DataFrame(importancesRF, columns=['Weight'], index=X_train_2.columns)\n",
    "feat_imp1.sort_values('Weight', inplace=True, ascending=False)\n",
    "feat_imp1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_imp = pd.DataFrame({'importance':decision_tree_2.feature_importances_})  \n",
    "# feat_imp['feature'] = X_train_2.columns\n",
    "# feat_imp.sort_values(by='importance', ascending=False, inplace=True)\n",
    "\n",
    "# feat_imp.sort_values(by='importance', inplace=True)\n",
    "# feat_imp = feat_imp.set_index('feature', drop=True)\n",
    "# feat_imp = feat_imp[len(feat_imp1)-16:len(feat_imp1)]\n",
    "# feat_imp.plot.barh(figsize=(5,5))\n",
    "# plt.xlabel('Importance Score')\n",
    "# plt.ylabel('16 Features')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = sklearn.metrics.mean_squared_error(y_test_2, y_predict_dt_2)  \n",
    "mae_dt_2 = sklearn.metrics.mean_absolute_error(y_test_2, y_predict_dt_2) \n",
    "\n",
    "rmse_dt_2 = math.sqrt(mse)  \n",
    "\n",
    "print(\"RMSE = \", rmse_dt_2)\n",
    "print(\"MAE = \", mae_dt_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Gradient boosting regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_boosting_tree_2 = GradientBoostingRegressor(n_estimators=50, learning_rate = 0.06, max_features = 1, \n",
    "                                               max_depth = 50, random_state=42)\n",
    "\n",
    "grad_boosting_tree_2.fit(X_train_2, y_train_2)\n",
    "y_predict_gb_2 = grad_boosting_tree_2.predict(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importancesRF = grad_boosting_tree_2.feature_importances_\n",
    "feat_imp1 = pd.DataFrame(importancesRF, columns=['Weight'], index=X_train_2.columns)\n",
    "feat_imp1.sort_values('Weight', inplace=True, ascending=False)\n",
    "feat_imp1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_imp = pd.DataFrame({'importance':grad_boosting_tree_2.feature_importances_})  \n",
    "# feat_imp['feature'] = X_train_2.columns\n",
    "# feat_imp.sort_values(by='importance', ascending=False, inplace=True)\n",
    "\n",
    "# feat_imp.sort_values(by='importance', inplace=True)\n",
    "# feat_imp = feat_imp.set_index('feature', drop=True)\n",
    "# feat_imp = feat_imp[len(feat_imp1)-16:len(feat_imp1)]\n",
    "# feat_imp.plot.barh(figsize=(5,5))\n",
    "# plt.xlabel('Importance Score')\n",
    "# plt.ylabel('16 Features')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = sklearn.metrics.mean_squared_error(y_test_2, y_predict_gb_2)  \n",
    "mae_gb_2 = sklearn.metrics.mean_absolute_error(y_test_2, y_predict_gb_2) \n",
    "\n",
    "rmse_gb_2 = math.sqrt(mse)  \n",
    "\n",
    "print(\"RMSE = \", rmse_gb_2)\n",
    "print(\"MAE = \", mae_gb_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(grad_boosting_tree_2)\n",
    "shap_values = explainer.shap_values(X_test_2)\n",
    "\n",
    "shap.force_plot(explainer.expected_value, shap_values[0,:], X_test_2.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {'Model': ['Random Forest', 'Random Forest', 'Decision Tree', 'Decision Tree',\n",
    "                  'Gradient Boosting', 'Gradient Boosting'],\n",
    "        'Test set': ['With nearest_airbnb_price', 'Without nearest_airbnb_price', \n",
    "                     'With nearest_airbnb_price', 'Without nearest_airbnb_price', \n",
    "                     'With nearest_airbnb_price', 'Without nearest_airbnb_price'],\n",
    "        'MAE': [mae_rf_2, mae_rf_1, mae_dt_2, mae_dt_1, mae_gb_2, mae_gb_1]}\n",
    "df_scores = pd.DataFrame(data)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.barplot(x=\"Model\", y=\"MAE\", hue=\"Test set\", data=df_scores)\n",
    "ax.set_title('MAE for different models and test dataset')\n",
    "\n",
    "ax.set_facecolor('#f2f2f2')\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(format(p.get_height(), '.2f'), \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha = 'center', va = 'center', \n",
    "                xytext = (0, 10), \n",
    "                textcoords = 'offset points', fontsize=10)\n",
    "plt.savefig('barplot_mae.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Model': ['Random Forest', 'Random Forest', 'Decision Tree', 'Decision Tree',\n",
    "                  'Gradient Boosting', 'Gradient Boosting'],\n",
    "        'Test set': ['With nearest_airbnb_price', 'Without nearest_airbnb_price', \n",
    "                     'With nearest_airbnb_price', 'Without nearest_airbnb_price', \n",
    "                     'With nearest_airbnb_price', 'Without nearest_airbnb_price'],\n",
    "        'RMSE': [rmse_rf_2, rmse_rf_1, rmse_dt_2, rmse_dt_1, rmse_gb_2, rmse_gb_1]}\n",
    "df_scores = pd.DataFrame(data)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.barplot(x=\"Model\", y=\"RMSE\", hue=\"Test set\", data=df_scores)\n",
    "ax.set_title('RMSE for different models and test dataset')\n",
    "\n",
    "ax.set_facecolor('#f2f2f2')\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(format(p.get_height(), '.2f'), \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha = 'center', va = 'center', \n",
    "                xytext = (0, 10), \n",
    "                textcoords = 'offset points', fontsize=10)\n",
    "plt.savefig('barplot_rmse.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is an emsemble technique that is able to perform Regression tasks with the use of multiple decision trees and a technique that is called Bootstrap aggregation (Bagging). The idea behind this technique is to combine multiple results of decision trees in its prediction rather than replying on individual decision trees, thus reduces the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance provides a score that indicates how useful or important each feature was in the construction of the decision trees within the model. The higher its relative importance, the more a variable is used to make key decisions within decision trees.\n",
    "\n",
    "Therefore, feature importance can be used to interpret our data to understand the most important features that define our predictions. In this case, looking at the bar chart above, the predictor variable that is associated with a longer bar means that the variable has a higher importance in the Random Tree Regression Model in predicting price."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
